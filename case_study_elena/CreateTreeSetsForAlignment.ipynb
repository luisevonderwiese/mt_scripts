{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1881efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tree sets with 100 raxml-ng runs with interim trees, removing duplicates etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9801ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load LuiseUtil.py\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "from ete3 import Tree\n",
    "from Bio import Phylo\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from codecs import decode\n",
    "import struct\n",
    "\n",
    "from Bio import Phylo, AlignIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.AlignIO.PhylipIO import PhylipWriter\n",
    "\n",
    "\n",
    "raxml_ng_path = './../../tools/raxml-ng/build/bin/raxml-ng'\n",
    "standard_raxml_path = './../../tools/standard-RAxML-master/raxmlHPC-AVX '\n",
    "\n",
    "tree_dir = 'data/trees/'\n",
    "alignment_dir = 'data/language_alignments/'\n",
    "sitelh_dir = 'data/siteLH/'\n",
    "drawings_dir = 'output/drawings/'\n",
    "weight_calibration_dir = 'data/weight_calibration/'\n",
    "site_congruence_dir = 'data/site_congruence/'\n",
    "lh_dir = 'data/lh/'\n",
    "indices_dir = 'data/indices/'\n",
    "deltas_dir = \"data/trait_association/delta_statistics/\"\n",
    "\n",
    "\n",
    "#tree_space_name = 'space.trees'\n",
    "geo_tree_name = \"geo_duration.tree\"\n",
    "cognate_tree_name = \"cognate_ie_compatible.tree\"\n",
    "cognate_ml_tree_name = \"cognate_ml.tree\"\n",
    "\n",
    "morpho_alignment_name = \"morpho.phy\"\n",
    "\n",
    "\n",
    "\n",
    "def read_trees_from_ete(tree_set_names):\n",
    "    trees = []\n",
    "    for tree_set in tree_set_names:\n",
    "        l_file = open(tree_dir + tree_set, 'r')\n",
    "        lines = l_file.readlines()\n",
    "        for line in lines:\n",
    "            trees.append(Tree(line))\n",
    "    return trees\n",
    "\n",
    "#def read_tree_space_ete():\n",
    "#    return read_trees_from_ete([tree_space_name])\n",
    "\n",
    "\n",
    "def eliminate_topological_duplicates_ete(tree_set_names, out_file_name):\n",
    "    unique_list = []\n",
    "    tree_set_ete = read_trees_from_ete(tree_set_names)\n",
    "    i = 0\n",
    "    for t1 in tree_set_ete:\n",
    "        unique = True\n",
    "        for t2 in unique_list:\n",
    "            rf = rf_distance_ete(t1, t2)\n",
    "            if rf == 0:\n",
    "                unique = False\n",
    "                break\n",
    "        if unique:\n",
    "            unique_list.append(t1)\n",
    "        i = i + 1\n",
    "    file_name = tree_dir + out_file_name\n",
    "    with open(file_name, 'w+') as tree_file:\n",
    "        for tree in unique_list:\n",
    "            tree_file.write(tree.write()+\"\\n\")\n",
    "    print(file_name + \" created\")\n",
    "\n",
    "def set_neg_branches_zero_ete(tree):\n",
    "    for node in tree.traverse(\"postorder\"):\n",
    "        if node.dist < 0:\n",
    "            node.dist = 0\n",
    "    return tree\n",
    "\n",
    "def set_neg_branches_zero(tree_set_name):\n",
    "    trees = read_trees_from_ete([tree_set_name])\n",
    "    for tree in trees:\n",
    "        tree = set_neg_branches_zero_ete(tree)\n",
    "    file_name = tree_dir + tree_set_name\n",
    "    with open(file_name, 'w+') as tree_file:\n",
    "        for tree in trees:\n",
    "            tree_file.write(tree.write()+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#def create_tree_space_from(tree_set_names):\n",
    "#    tree_space_ete = read_trees_from_ete(tree_set_names)\n",
    "#    file_name = tree_dir + tree_space_name\n",
    "#    with open(file_name, 'w+') as tree_file:\n",
    "#        for tree in tree_space_ete:\n",
    "#            tree_file.write(tree.write()+\"\\n\")\n",
    "#    print(str(len(tree_space_ete)) + \" trees written to \" + file_name)\n",
    "\n",
    "def read_geo_tree_ete():\n",
    "    return Tree(tree_dir + geo_tree_name)\n",
    "\n",
    "def read_cognate_tree_ete():\n",
    "    return Tree(tree_dir + cognate_tree_name)\n",
    "\n",
    "def rf_distance_ete(t1, t2):\n",
    "    rf, max_rf, common_leaves, parts_t1, parts_t2,discard_t1, discart_t2 = t1.robinson_foulds(t2, unrooted_trees = True)\n",
    "    if max_rf == 0:\n",
    "        print(\"?!\")\n",
    "        return 0\n",
    "    return rf/max_rf\n",
    "\n",
    "def rf_distances_ete(ref_tree, tree_set):\n",
    "    distances = []\n",
    "    for tree in tree_set:\n",
    "        distances.append(rf_distance_ete(ref_tree, tree))\n",
    "    return distances\n",
    "\n",
    "\n",
    "def calculate_rf_distances_raxml(ref_tree_name, tree_set_names):\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    os.mkdir(\"temp/\")\n",
    "    dir_string = tree_dir + ref_tree_name\n",
    "    for tree_set in tree_set_names:\n",
    "        dir_string = dir_string + tree_dir + tree_set\n",
    "    os.system(\"cat \" + dir_string + \" > temp/all.trees\")\n",
    "    os.system(raxml_ng_path + \" --rfdist --tree temp/all.trees --prefix temp/foo > temp/bar.txt\")\n",
    "    l_file = open('temp/foo.raxml.rfDistances', 'r')\n",
    "    lines = l_file.readlines()\n",
    "    i = 0\n",
    "    line = lines[i].split(\"\\t\")\n",
    "    distances = []\n",
    "    while(line[0] == '0'):\n",
    "        distances.append(float(line[3]))\n",
    "        i+=1\n",
    "        line = lines[i].split(\"\\t\")\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def evaluate_lh_raxml(tree_name, alignment_name, optimize = True):\n",
    "    optimize_string = \"\"\n",
    "    if not optimize:\n",
    "        optimize_string = \" --opt-branches off \"\n",
    "    os.system(raxml_ng_path + ' --evaluate --msa ' + alignment_dir + alignment_name +\n",
    "            ' --threads 2 --model BIN+G --tree '  + tree_dir + tree_name +  ' --prefix foo --nofiles' +\n",
    "              optimize_string + '> out.txt')\n",
    "    l_file = open('out.txt', 'r')\n",
    "    lines = l_file.readlines()\n",
    "    lh = 0\n",
    "    for line in lines:\n",
    "        if(line.startswith('Final LogLikelihood:')):\n",
    "            lh = float(line.split(\" \")[2].strip())\n",
    "    os.remove(\"out.txt\")\n",
    "    return lh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_site_lh_raxml_ete(tree_ete, alignment_name, optimize= True):\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    os.mkdir(\"temp/\")\n",
    "    tree_ete.write(outfile=\"temp/foo.tree\")\n",
    "    optimize_string = \"\"\n",
    "    if not optimize:\n",
    "        optimize_string = \" --opt-branches off \"\n",
    "    os.system(raxml_ng_path + ' --sitelh --msa ' + alignment_dir + alignment_name +\n",
    "            ' --threads 2 --model BIN+G --tree temp/foo.tree --prefix temp/foo ' +\n",
    "              optimize_string + '> temp/bar.txt')\n",
    "    l_file = open('temp/foo.raxml.log', 'r')\n",
    "    lines = l_file.readlines()\n",
    "    lh = 0\n",
    "    for line in lines:\n",
    "        if(line.startswith('Final LogLikelihood:')):\n",
    "            lh = float(line.split(\" \")[2].strip())\n",
    "    with open('temp/foo.raxml.siteLH' , 'r') as file:\n",
    "        data = (file.read().replace('\\n', '')).split(\" \")\n",
    "    #siteLH = [float(data[i]) for i in range(5, len(data))]\n",
    "    siteLH = [data[i] for i in range(5, len(data))]\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    return [lh, siteLH]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_tree_with_phylo(tree_name, save = False):\n",
    "    tree = Phylo.read(tree_dir + tree_name, \"newick\")\n",
    "    tree.ladderize()\n",
    "    fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "    axes = fig.add_subplot(1, 1, 1)\n",
    "    axes.set_title(tree_name)\n",
    "    Phylo.draw(tree, axes=axes, do_show=False)\n",
    "    if save:\n",
    "        plt.savefig(drawings_dir + tree_name + '.png', dpi=fig.dpi)\n",
    "\n",
    "\n",
    "def fix_beast_output(tree_set_name):\n",
    "    beast_file = open(tree_dir + tree_set_name, 'r')\n",
    "    lines = beast_file.readlines()\n",
    "    i = 0\n",
    "    while not lines[i].startswith(\"\\tTranslate\"):\n",
    "        i = i+1\n",
    "    translate = []\n",
    "    while not lines[i].startswith(\";\"):\n",
    "        if lines[i].endswith(\",\\n\"):\n",
    "            translate.append(lines[i].split(\" \")[-1][:-2])\n",
    "        else:\n",
    "            translate.append(lines[i].split(\" \")[-1][:-1])\n",
    "        i=i+1\n",
    "    i = i+1\n",
    "    with open(tree_dir + rm_end(tree_set_name) + \"_fixed.trees\" , 'w+') as fixed_file:\n",
    "        for j in range(i, len(lines)-1):\n",
    "            tree = Tree(lines[j].split(\" \")[-1])\n",
    "            for leaf in tree.iter_leaves():\n",
    "                leaf.name = translate[int(leaf.name)]\n",
    "            fixed_file.write(tree.write() + \"\\n\")\n",
    "\n",
    "def rm_end(file_name):\n",
    "    return '.'.join(file_name.split('.') [:-1])\n",
    "\n",
    "def lh_file_name(tree_set_name, alignment_name, optimize):\n",
    "    optimize_string = \"_opt-branches=\"\n",
    "    if optimize:\n",
    "        optimize_string = optimize_string + \"on\"\n",
    "    else:\n",
    "        optimize_string = optimize_string + \"off\"\n",
    "    return lh_dir + rm_end(alignment_name) + '_' + rm_end(tree_set_name)  + optimize_string + '.lh'\n",
    "\n",
    "def lh_raw_file_name(tree_set_name, alignment_name, optimize):\n",
    "    optimize_string = \"_opt-branches=\"\n",
    "    if optimize:\n",
    "        optimize_string = optimize_string + \"on\"\n",
    "    else:\n",
    "        optimize_string = optimize_string + \"off\"\n",
    "    return lh_dir + rm_end(alignment_name) + '_' + rm_end(tree_set_name)  + optimize_string + '_raw.lh'\n",
    "\n",
    "\n",
    "def site_lh_file_name(tree_name, alignment_name, optimize):\n",
    "    optimize_string = \"_opt-branches=\"\n",
    "    if optimize:\n",
    "        optimize_string = optimize_string + \"on\"\n",
    "    else:\n",
    "        optimize_string = optimize_string + \"off\"\n",
    "    return sitelh_dir + rm_end(alignment_name) + '_' + rm_end(tree_name)  + optimize_string + '.raxml.siteLH'\n",
    "\n",
    "def site_lh_raw_file_name(tree_name, alignment_name, optimize):\n",
    "    optimize_string = \"_opt-branches=\"\n",
    "    if optimize:\n",
    "        optimize_string = optimize_string + \"on\"\n",
    "    else:\n",
    "        optimize_string = optimize_string + \"off\"\n",
    "    return sitelh_dir + rm_end(alignment_name) + '_' + rm_end(tree_name)  + optimize_string + '_raw.raxml.siteLH'\n",
    "\n",
    "def weight_calibration_file_name(tree_name, alignment_name):\n",
    "    return weight_calibration_dir + rm_end(alignment_name) + '_' + rm_end(tree_name)  + '.raxml.weightCalibration'\n",
    "\n",
    "def site_congruence_file_name(tree_name, alignment_name):\n",
    "    return site_congruence_dir + rm_end(alignment_name) + '_' + rm_end(tree_name)  + '.raxml.siteCongruence'\n",
    "\n",
    "def optimized_tree_file_name(tree_name, alignment_name):\n",
    "    return tree_dir + rm_end(tree_name) + '_optimized_' + rm_end(alignment_name)  + '.tree'\n",
    "\n",
    "def ml_trees_file_name(alignment_name, start_trees = \"\"):\n",
    "    if start_trees == \"\":\n",
    "        return tree_dir + rm_end(alignment_name) + \".raxml.mlTrees\"\n",
    "    else:\n",
    "        return tree_dir + rm_end(alignment_name) + \"_\" + start_trees + \".raxml.mlTrees\"\n",
    "\n",
    "def best_tree_file_name(alignment_name, start_trees = \"\"):\n",
    "    if start_trees == \"\":\n",
    "        return tree_dir + rm_end(alignment_name) + \".raxml.bestTree\"\n",
    "    else:\n",
    "        return tree_dir + rm_end(alignment_name) + \"_\" + start_trees + \".raxml.bestTree\"\n",
    "\n",
    "def deltas_file_name(tree_name, alignment_name):\n",
    "    return deltas_dir + rm_end(alignment_name) + '_' + rm_end(tree_name)  + '.deltas'\n",
    "\n",
    "\n",
    "def read_lhs(tree_set_name, alignment_name, optimize):\n",
    "    lhs = []\n",
    "    site_lhs = []\n",
    "    with open(lh_file_name(tree_set_name, alignment_name, optimize) , 'r') as file:\n",
    "        lines = file.read().split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        line_data = line.split(\"\\t\")\n",
    "        lhs.append(float(line_data[0]))\n",
    "        site_lhs.append([float(el) for el in line_data[1].split(\" \")[:-1]])\n",
    "    return (lhs, site_lhs)\n",
    "\n",
    "def read_lhs_raw(tree_set_name, alignment_name, optimize):\n",
    "    lhs = []\n",
    "    site_lhs = []\n",
    "    with open(lh_raw_file_name(tree_set_name, alignment_name, optimize) , 'r') as file:\n",
    "        lines = file.read().split(\"\\n\")\n",
    "    for line in lines[:-1]:\n",
    "        line_data = line.split(\"\\t\")\n",
    "        lhs.append(float(line_data[0]))\n",
    "        site_lhs.append([bin_to_float(el) for el in line_data[1].split(\" \")[:-1]])\n",
    "    return (lhs, site_lhs)\n",
    "\n",
    "def read_site_lh(tree_name, alignment_name, optimize):\n",
    "    with open(site_lh_file_name(tree_name, alignment_name, optimize) , 'r') as file:\n",
    "        data = (file.read().replace('\\n', '')).split(\" \")\n",
    "    return [float(data[i]) for i in range(5, len(data))]\n",
    "\n",
    "def read_site_lh_raw(tree_name, alignment_name, optimize):\n",
    "    with open(site_lh_raw_file_name(tree_name, alignment_name, optimize) , 'r') as file:\n",
    "        data = (file.read().replace('\\n', '')).split(\" \")\n",
    "    return [bin_to_float(data[i]) for i in range(5, len(data))]\n",
    "\n",
    "def read_weight_calibration(tree_name, alignment_name):\n",
    "    with open(weight_calibration_file_name(tree_name, alignment_name) , 'r') as file:\n",
    "        data = file.read().split(\" \")\n",
    "    return [int(data[i]) for i in range(len(data) - 1)]\n",
    "\n",
    "def read_site_congruence(tree_name, alignment_name):\n",
    "    with open(site_congruence_file_name(tree_name, alignment_name) , 'r') as file:\n",
    "        data = file.read().split(\"\\n\")\n",
    "    return [float(data[i].split(\" \")[1]) for i in range(len(data) - 1)]\n",
    "\n",
    "def read_optimized_tree(tree_name, alignment_name):\n",
    "    return Tree(optimized_tree_file_name(tree_name, alignment_name))\n",
    "\n",
    "def read_ml_trees(alignment_name, start_trees = \"\"):\n",
    "    tree_file = open(ml_trees_file_name(alignment_name, start_trees))\n",
    "    return [Tree(line[:-1]) for line in tree_file.readlines()]\n",
    "\n",
    "def read_best_tree(alignment_name, start_trees = \"\"):\n",
    "    tree_file = open(best_tree_file_name(alignment_name, start_trees))\n",
    "    return Tree(tree_file.readlines()[0][:-1])\n",
    "\n",
    "\n",
    "def read_deltas(alignment_name, tree_name):\n",
    "    deltas_file = open(deltas_file_name(alignment_name, tree_name))\n",
    "    return [float(line) for line in deltas_file.readlines()]\n",
    "\n",
    "def calculate_lhs_raxml(tree_set_name, alignment_name, optimize = False):\n",
    "    tree_set = read_trees_from_ete([tree_set_name])\n",
    "    results = [calculate_site_lh_raxml_ete(tree, alignment_name, optimize) for tree in tree_set]\n",
    "    with open(lh_raw_file_name(tree_set_name, alignment_name, optimize), 'w+') as out_file:\n",
    "        for result in results:\n",
    "            out_file.write(str(result[0]))\n",
    "            out_file.write(\"\\t\")\n",
    "            for site_lh in result[1]:\n",
    "                #out_file.write(str(site_lh))\n",
    "                out_file.write(site_lh)\n",
    "                out_file.write(\" \")\n",
    "            out_file.write(\"\\n\")\n",
    "\n",
    "def calculate_site_lh_raxml(tree_name, alignment_name, optimize= True):\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    os.mkdir(\"temp/\")\n",
    "    optimize_string = \"\"\n",
    "    if not optimize:\n",
    "        optimize_string = \" --opt-branches off \"\n",
    "    os.system(raxml_ng_path + ' --sitelh --msa ' + alignment_dir + alignment_name +\n",
    "            ' --threads 2 --model BIN+G --tree '  + tree_dir + tree_name +  ' --prefix temp/foo ' +\n",
    "              optimize_string + '> temp/bar.txt')\n",
    "    l_file = open('temp/foo.raxml.log', 'r')\n",
    "    lines = l_file.readlines()\n",
    "    lh = 0\n",
    "    for line in lines:\n",
    "        if(line.startswith('Final LogLikelihood:')):\n",
    "            lh = float(line.split(\" \")[2].strip())\n",
    "    #os.system(\"cat temp/foo.raxml.siteLH > \" + site_lh_file_name(tree_name, alignment_name, optimize))\n",
    "    os.system(\"cat temp/foo.raxml.siteLH > \" + site_lh_raw_file_name(tree_name, alignment_name, optimize))\n",
    "    with open('temp/foo.raxml.siteLH' , 'r') as file:\n",
    "        data = (file.read().replace('\\n', '')).split(\" \")\n",
    "    #siteLH = [float(data[i]) for i in range(5, len(data))]\n",
    "    siteLH = [data[i] for i in range(5, len(data))]\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    return [lh, siteLH]\n",
    "\n",
    "def calculate_weight_calibration_raxml(tree_name, alignment_name):\n",
    "    os.system(standard_raxml_path + ' -f u -p 12345 -t ' + tree_dir + tree_name +\n",
    "              ' -m BINGAMMA -s ' + alignment_dir + alignment_name +\n",
    "              ' -n calibration > bar.txt')\n",
    "    os.system('cat RAxML_weights.calibration > '\n",
    "              + weight_calibration_file_name(tree_name, alignment_name))\n",
    "    os.remove('bar.txt')\n",
    "    os.remove('RAxML_weights.calibration')\n",
    "    os.remove('RAxML_info.calibration')\n",
    "\n",
    "def calculate_site_congruence_raxml(tree_name, alignment_name):\n",
    "    os.system(standard_raxml_path + ' -f S -t ' + tree_dir + tree_name +\n",
    "              ' -m BINGAMMA -s ' + alignment_dir + alignment_name +\n",
    "              ' -n congruence > bar.txt')\n",
    "    os.system('cat RAxML_SiteSpecificPlacementBias.congruence > '\n",
    "              + site_congruence_file_name(tree_name, alignment_name))\n",
    "    os.remove('bar.txt')\n",
    "    os.remove('RAxML_SiteSpecificPlacementBias.congruence')\n",
    "    os.remove('RAxML_info.congruence')\n",
    "\n",
    "def calculate_optimized_tree_raxml(tree_name, alignment_name):\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    os.mkdir(\"temp/\")\n",
    "    os.system(raxml_ng_path + ' --evaluate --msa ' + alignment_dir + alignment_name +\n",
    "            ' --threads 2 --model BIN+G --tree '  + tree_dir + tree_name +  ' --prefix temp/foo ' + '> out.txt')\n",
    "    os.system('cat temp/foo.raxml.bestTree > ' + tree_dir + rm_end(tree_name) + \"_optimized_\" + rm_end(alignment_name) + '.tree')\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "\n",
    "\n",
    "def calculate_ml_trees_raxml(alignment_name, start_trees = \"\"):\n",
    "    shutil.rmtree(\"temp/\", ignore_errors=True)\n",
    "    os.mkdir(\"temp/\")\n",
    "    if start_trees == \"\":\n",
    "        os.system(raxml_ng_path + ' --msa ' + alignment_dir + alignment_name +\n",
    "            ' --threads 2 --seed 2 --model BIN+G --prefix temp/foo > temp/bar.txt')\n",
    "    else:\n",
    "        os.system(raxml_ng_path + ' --msa ' + alignment_dir + alignment_name +\n",
    "            ' --tree ' + start_trees +\n",
    "            ' --threads 2 --seed 2 --model BIN+G --prefix temp/foo > temp/bar.txt')\n",
    "    os.system('cat temp/foo.raxml.mlTrees > ' + ml_trees_file_name(alignment_name, start_trees))\n",
    "    os.system('cat temp/foo.raxml.bestTree > ' + best_tree_file_name(alignment_name, start_trees))\n",
    "\n",
    "\n",
    "\n",
    "def get_site_lh(tree_name, alignment_name, optimize):\n",
    "    if not os.path.isfile(site_lh_file_name(tree_name, alignment_name, optimize)):\n",
    "        print(\"Currently not possible, use site_lh_raw\")\n",
    "        #calculate_site_lh_raxml(tree_name, alignment_name, optimize)\n",
    "    return read_site_lh(tree_name, alignment_name, optimize)\n",
    "\n",
    "def get_site_lh_raw(tree_name, alignment_name, optimize):\n",
    "    if not os.path.isfile(site_lh_raw_file_name(tree_name, alignment_name, optimize)):\n",
    "        calculate_site_lh_raxml(tree_name, alignment_name, optimize)\n",
    "    return read_site_lh_raw(tree_name, alignment_name, optimize)\n",
    "\n",
    "\n",
    "def get_weight_calibration(tree_name, alignment_name):\n",
    "    if not os.path.isfile(weight_calibration_file_name(tree_name, alignment_name)):\n",
    "        calculate_weight_calibration_raxml(tree_name, alignment_name)\n",
    "    return read_weight_calibration(tree_name, alignment_name)\n",
    "\n",
    "def get_site_congruence(tree_name, alignment_name):\n",
    "    if not os.path.isfile(site_congruence_file_name(tree_name, alignment_name)):\n",
    "        calculate_site_congruence_raxml(tree_name, alignment_name)\n",
    "    return read_site_congruence(tree_name, alignment_name)\n",
    "\n",
    "def get_optimized_tree(tree_name, alignment_name):\n",
    "    if not os.path.isfile(optimized_tree_file_name(tree_name, alignment_name)):\n",
    "        calculate_optimized_tree_raxml(tree_name, alignment_name)\n",
    "    return read_optimized_tree(tree_name, alignment_name)\n",
    "\n",
    "def get_double_optimized_tree(tree_name, alignment_name):\n",
    "    if not os.path.isfile(optimized_tree_file_name(tree_name, alignment_name)):\n",
    "        calculate_optimized_tree_raxml(tree_name, alignment_name)\n",
    "    optimized_tree_name = optimized_tree_file_name(tree_name, alignment_name).split('/')[-1]\n",
    "    if not os.path.isfile(optimized_tree_file_name(optimized_tree_name, alignment_name)):\n",
    "        calculate_optimized_tree_raxml(optimized_tree_name, alignment_name)\n",
    "    return read_optimized_tree(optimized_tree_name, alignment_name)\n",
    "\n",
    "\n",
    "def get_optimized_tree(tree_name, alignment_name):\n",
    "    if not os.path.isfile(optimized_tree_file_name(tree_name, alignment_name)):\n",
    "        calculate_optimized_tree_raxml(tree_name, alignment_name)\n",
    "    return read_optimized_tree(tree_name, alignment_name)\n",
    "\n",
    "\n",
    "def get_lhs(tree_set_name, alignment_name, optimize):\n",
    "    if not os.path.isfile(lh_file_name(tree_set_name, alignment_name, optimize)):\n",
    "        #calculate_lhs_raxml(tree_set_name, alignment_name, optimize)\n",
    "        print(\"Currently not possible, use lhs_raw\")\n",
    "    return read_lhs(tree_set_name, alignment_name, optimize)\n",
    "\n",
    "def get_lhs_raw(tree_set_name, alignment_name, optimize):\n",
    "    if not os.path.isfile(lh_raw_file_name(tree_set_name, alignment_name, optimize)):\n",
    "        calculate_lhs_raxml(tree_set_name, alignment_name, optimize)\n",
    "    return read_lhs_raw(tree_set_name, alignment_name, optimize)\n",
    "\n",
    "\n",
    "def get_ml_trees(alignment_name, start_trees = \"\"):\n",
    "    if not os.path.isfile(ml_trees_file_name(alignment_name, start_trees)):\n",
    "        calculate_ml_trees_raxml(alignment_name, start_trees)\n",
    "    return read_ml_trees(alignment_name, start_trees)\n",
    "\n",
    "def get_best_tree(alignment_name, start_trees = \"\"):\n",
    "    if not os.path.isfile(best_tree_file_name(alignment_name, start_trees)):\n",
    "        calculate_ml_trees_raxml(alignment_name, start_trees)\n",
    "    return read_best_tree(alignment_name, start_trees)\n",
    "\n",
    "\n",
    "def get_deltas(tree_name, alignment_name):\n",
    "    if not os.path.isfile(deltas_file_name(alignment_name, tree_name)):\n",
    "        print(\"Deltas must be calculated in R!\")\n",
    "    return read_deltas(alignment_name, tree_name)\n",
    "\n",
    "def average_branch_length(tree_set):\n",
    "    avg = 0\n",
    "    cnt = 0\n",
    "    for tree in tree_set:\n",
    "        for node in tree.traverse():\n",
    "            avg = avg + node.dist\n",
    "            cnt = cnt + 1\n",
    "    avg = avg / cnt\n",
    "    return avg\n",
    "\n",
    "\n",
    "\n",
    "def interval_branch_length(tree_set):\n",
    "    lower = 1\n",
    "    upper = 0\n",
    "    for tree in tree_set:\n",
    "        for node in tree.traverse():\n",
    "            lower = min(lower, node.dist)\n",
    "            upper = max(upper, node.dist)\n",
    "    return (lower, upper)\n",
    "\n",
    "\n",
    "\n",
    "def variance_branch_length(tree_set):\n",
    "    avg = average_branch_length(tree_set)\n",
    "    var = 0\n",
    "    cnt = 0\n",
    "    for tree in tree_set:\n",
    "        for node in tree.traverse():\n",
    "            diff = node.dist - avg\n",
    "            var = var + (diff * diff)\n",
    "            cnt = cnt + 1\n",
    "    return var / cnt\n",
    "\n",
    "\n",
    "def bin_to_float(b):\n",
    "    return struct.unpack('>d', decode('%%0%dx' % (8 << 1) % int(b, 2), 'hex')[-8:])[0]\n",
    "\n",
    "\n",
    "def rf_dist_matrix(tree_dict):\n",
    "    for i, name1 in enumerate(tree_dict):\n",
    "        for j, name2 in enumerate(tree_dict):\n",
    "            if name2 <= name1:\n",
    "                continue\n",
    "            rf_str = str(rf_distance_ete(tree_dict[name1], tree_dict[name2]))\n",
    "            print(\"RF distance of \" + name1 + \" to \" + name2 + \": \" + rf_str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kit_green = \"#009682\"\n",
    "kit_orange = \"#DF9B1B\"\n",
    "kit_blue = \"#0A64AA\"\n",
    "kit_maigreen = \"#8CB63C\"\n",
    "kit_yellow = \"#FCE500\"\n",
    "kit_red = \"#A22223\"\n",
    "kit_lila = \"#A3107C\"\n",
    "kit_cyan = \"#23A1E0\"\n",
    "\n",
    "names_dict = {\n",
    "    \"cognate_ie_compatible.tree\" : \"$T_C$\",\n",
    "    \"geo_duration.tree\" : \"$T_G$\",\n",
    "\n",
    "    \"morpho.phy\" : \"$A$\",\n",
    "    \"morpho_filtered_indsToUse.phy\" : \"$\\hat{A}$\",\n",
    "    \"cognate.phy\" : \"$A_C$\",\n",
    "\n",
    "    \"significant_all_interim.trees\" : \"$\\mathcal{T}_{\\t{im}}(\\hat{A})$\",\n",
    "    \"all_interim.trees\" : \"$\\mathcal{T}_{\\t{im}}(A)$\",\n",
    "    \"filtered_all_interim.trees\" : \"$\\mathcal{T}_{\\t{im}}(A_f)$\",\n",
    "\n",
    "    \"significant_all_start.trees\" : \"$\\mathcal{T}_{\\t{st}}(\\hat{A})$\",\n",
    "    \"all_start.trees\" : \"$\\mathcal{T}_{\\t{st}}(A)$\",\n",
    "    \"filtered_all_start.trees\" : \"$\\mathcal{T}_{\\t{st}}(A_f)$\",\n",
    "\n",
    "    \"morpho_filtered_nj_final.phy\": \"$A_{NJ}$\",\n",
    "    \"morpho_filtered_pars_final.phy\": \"$A_{Pars}$\",\n",
    "    \"morpho_filtered_ml_final.phy\": \"$A_{ML}$\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def quartet_distance(tree_name1, tree_name2):\n",
    "    tree_name1 = os.path.join(tree_dir, tree_name1)\n",
    "    tree_name2 = os.path.join(tree_dir, tree_name2)\n",
    "    os.system(\"./../../tools/qdist/qdist \" + tree_name1 + \" \" + tree_name2 + \" >out.txt\")\n",
    "    qdist = float(open(\"out.txt\").readlines()[1].split(\"\\t\")[-1])\n",
    "    os.remove(\"out.txt\")\n",
    "    return qdist\n",
    "\n",
    "def quartet_distances(ref_tree_name, tree_set):\n",
    "    ref_tree_path  = os.path.join(tree_dir, ref_tree_name)\n",
    "    qdists = []\n",
    "    for tree in tree_set:\n",
    "        open(\"temp.tree\", 'w+').write(tree.write())\n",
    "        os.system(\"./../../tools/qdist/qdist temp.tree \" +  ref_tree_path + \" >out.txt\")\n",
    "        qdists.append(float(open(\"out.txt\").readlines()[1].split(\"\\t\")[-1]))\n",
    "    os.remove(\"out.txt\")\n",
    "    os.remove(\"temp.tree\")\n",
    "    return qdists\n",
    "\n",
    "def average_rf_distance_in_tree_set(tree_set_name):\n",
    "    trees = read_trees_from_ete([tree_set_name])\n",
    "    distances = []\n",
    "    if (len(trees) < 2):\n",
    "        return 0\n",
    "    for (i, tree1) in enumerate(trees):\n",
    "        for j in range(i+1, len(trees)):\n",
    "            tree2 = trees[j]\n",
    "            distances.append(rf_distance_ete(tree1, tree2))\n",
    "    return sum(distances) / len(distances)\n",
    "\n",
    "def num_trees(tree_set_name):\n",
    "    return len(open(tree_dir + tree_set_name).readlines())\n",
    "\n",
    "def average_rf_distance_to_ref_tree(tree_set_name, tree_name):\n",
    "    tree = Tree(tree_dir + tree_name)\n",
    "    trees = read_trees_from_ete([tree_set_name])\n",
    "    dists = rf_distances_ete(tree, trees)\n",
    "    return sum(dists)/len(dists)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8199adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAxML-NG v. 1.1.0-master released on 04.08.2022 by The Exelixis Lab.\n",
      "Developed by: Alexey M. Kozlov and Alexandros Stamatakis.\n",
      "Contributors: Diego Darriba, Tomas Flouri, Benoit Morel, Sarah Lutteropp, Ben Bettisworth.\n",
      "Latest version: https://github.com/amkozlov/raxml-ng\n",
      "Questions/problems/suggestions? Please visit: https://groups.google.com/forum/#!forum/raxml\n",
      "\n",
      "System: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz, 2 cores, 15 GB RAM\n",
      "\n",
      "RAxML-NG was called at 07-Apr-2023 16:44:10 as follows:\n",
      "\n",
      "./../../tools/raxml-ng/build/bin/raxml-ng --msa data/language_alignments/morpho_filtered_ml_final.phy --model BIN+G --prefix data/trees/pavlos_ml_pars100rand100bing --threads 2 --seed 2 --tree pars{100},rand{100}\n",
      "\n",
      "Analysis options:\n",
      "  run mode: ML tree search\n",
      "  start tree(s): random (100) + parsimony (100)\n",
      "  random seed: 2\n",
      "  tip-inner: OFF\n",
      "  pattern compression: ON\n",
      "  per-rate scalers: OFF\n",
      "  site repeats: ON\n",
      "  fast spr radius: AUTO\n",
      "  spr subtree cutoff: 1.000000\n",
      "  branch lengths: proportional (ML estimate, algorithm: NR-FAST)\n",
      "  SIMD kernels: AVX2\n",
      "  parallelization: coarse-grained (auto), PTHREADS (2 threads), thread pinning: OFF\n",
      "\n",
      "[00:00:00] Reading alignment from file: data/language_alignments/morpho_filtered_ml_final.phy\n",
      "[00:00:00] Loaded alignment with 46 taxa and 44 sites\n",
      "\n",
      "WARNING: Sequences It and Sp are exactly identical!\n",
      "WARNING: Sequences Ice and Far are exactly identical!\n",
      "WARNING: Sequences Po and BelR are exactly identical!\n",
      "WARNING: Duplicate sequences found: 3\n",
      "\n",
      "NOTE: Reduced alignment (with duplicates and gap-only sites/taxa removed) \n",
      "NOTE: was saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bing.raxml.reduced.phy\n",
      "\n",
      "Alignment comprises 1 partitions and 44 patterns\n",
      "\n",
      "Partition 0: noname\n",
      "Model: BIN+FO+G4m\n",
      "Alignment sites / patterns: 44 / 44\n",
      "Gaps: 4.25 %\n",
      "Invariant sites: 0.00 %\n",
      "\n",
      "\n",
      "NOTE: Binary MSA file created: data/trees/pavlos_ml_pars100rand100bing.raxml.rba\n",
      "\n",
      "Parallelization scheme autoconfig: 2 worker(s) x 1 thread(s)\n",
      "\n",
      "Parallel reduction/worker buffer size: 1 KB  / 0 KB\n",
      "\n",
      "[00:00:00] Generating 100 random starting tree(s) with 46 taxa\n",
      "[00:00:00] Generating 100 parsimony starting tree(s) with 46 taxa\n",
      "[00:00:00] Data distribution: max. partitions/sites/weight per thread: 1 / 44 / 352\n",
      "[00:00:00] Data distribution: max. searches per worker: 100\n",
      "\n",
      "Starting ML tree search with 200 distinct starting trees\n",
      "\n",
      "[00:00:01] [worker #0] ML tree search #1, logLikelihood: -555.042463\n",
      "[00:00:02] [worker #0] ML tree search #3, logLikelihood: -557.542243\n",
      "[00:00:03] [worker #1] ML tree search #2, logLikelihood: -553.902725\n",
      "[00:00:04] [worker #0] ML tree search #5, logLikelihood: -555.045938\n",
      "[00:00:04] [worker #1] ML tree search #4, logLikelihood: -555.442350\n",
      "[00:00:05] [worker #0] ML tree search #7, logLikelihood: -554.789764\n",
      "[00:00:06] [worker #0] ML tree search #9, logLikelihood: -554.698998\n",
      "[00:00:06] [worker #1] ML tree search #6, logLikelihood: -553.902475\n",
      "[00:00:07] [worker #0] ML tree search #11, logLikelihood: -553.595735\n",
      "[00:00:07] [worker #1] ML tree search #8, logLikelihood: -553.599644\n",
      "[00:00:08] [worker #1] ML tree search #10, logLikelihood: -553.418945\n",
      "[00:00:08] [worker #0] ML tree search #13, logLikelihood: -556.322567\n",
      "[00:00:09] [worker #0] ML tree search #15, logLikelihood: -555.044726\n",
      "[00:00:10] [worker #1] ML tree search #12, logLikelihood: -553.900107\n",
      "[00:00:10] [worker #0] ML tree search #17, logLikelihood: -553.599560\n",
      "[00:00:11] [worker #1] ML tree search #14, logLikelihood: -555.200819\n",
      "[00:00:12] [worker #0] ML tree search #19, logLikelihood: -554.219559\n",
      "[00:00:13] [worker #0] ML tree search #21, logLikelihood: -555.693001\n",
      "[00:00:13] [worker #1] ML tree search #16, logLikelihood: -554.539954\n",
      "[00:00:14] [worker #0] ML tree search #23, logLikelihood: -553.888326\n",
      "[00:00:14] [worker #1] ML tree search #18, logLikelihood: -554.825061\n",
      "[00:00:15] [worker #0] ML tree search #25, logLikelihood: -554.790398\n",
      "[00:00:15] [worker #1] ML tree search #20, logLikelihood: -555.437130\n",
      "[00:00:16] [worker #0] ML tree search #27, logLikelihood: -554.789020\n",
      "[00:00:17] [worker #1] ML tree search #22, logLikelihood: -554.019355\n",
      "[00:00:17] [worker #0] ML tree search #29, logLikelihood: -554.785064\n",
      "[00:00:18] [worker #1] ML tree search #24, logLikelihood: -555.608692\n",
      "[00:00:18] [worker #0] ML tree search #31, logLikelihood: -553.888475\n",
      "[00:00:19] [worker #0] ML tree search #33, logLikelihood: -553.700596\n",
      "[00:00:19] [worker #1] ML tree search #26, logLikelihood: -553.701037\n",
      "[00:00:20] [worker #0] ML tree search #35, logLikelihood: -554.219708\n",
      "[00:00:21] [worker #1] ML tree search #28, logLikelihood: -555.810334\n",
      "[00:00:21] [worker #0] ML tree search #37, logLikelihood: -554.717104\n",
      "[00:00:21] [worker #1] ML tree search #30, logLikelihood: -555.043731\n",
      "[00:00:22] [worker #1] ML tree search #32, logLikelihood: -557.524518\n",
      "[00:00:23] [worker #0] ML tree search #39, logLikelihood: -555.443283\n",
      "[00:00:24] [worker #0] ML tree search #41, logLikelihood: -553.697088\n",
      "[00:00:24] [worker #1] ML tree search #34, logLikelihood: -554.008913\n",
      "[00:00:25] [worker #1] ML tree search #36, logLikelihood: -553.595785\n",
      "[00:00:25] [worker #0] ML tree search #43, logLikelihood: -554.618815\n",
      "[00:00:26] [worker #1] ML tree search #38, logLikelihood: -553.553527\n",
      "[00:00:27] [worker #1] ML tree search #40, logLikelihood: -553.595716\n",
      "[00:00:29] [worker #0] ML tree search #45, logLikelihood: -553.597441\n",
      "[00:00:30] [worker #1] ML tree search #42, logLikelihood: -553.944912\n",
      "[00:00:30] [worker #0] ML tree search #47, logLikelihood: -560.239322\n",
      "[00:00:31] [worker #1] ML tree search #44, logLikelihood: -554.222654\n",
      "[00:00:31] [worker #0] ML tree search #49, logLikelihood: -553.591994\n",
      "[00:00:32] [worker #1] ML tree search #46, logLikelihood: -553.595829\n",
      "[00:00:34] [worker #0] ML tree search #51, logLikelihood: -554.541294\n",
      "[00:00:34] [worker #1] ML tree search #48, logLikelihood: -555.819393\n",
      "[00:00:35] [worker #1] ML tree search #50, logLikelihood: -555.499535\n",
      "[00:00:35] [worker #0] ML tree search #53, logLikelihood: -553.602067\n",
      "[00:00:37] [worker #0] ML tree search #55, logLikelihood: -553.596351\n",
      "[00:00:37] [worker #1] ML tree search #52, logLikelihood: -553.596196\n",
      "[00:00:38] [worker #0] ML tree search #57, logLikelihood: -554.701364\n",
      "[00:00:40] [worker #1] ML tree search #54, logLikelihood: -553.674780\n",
      "[00:00:40] [worker #0] ML tree search #59, logLikelihood: -557.865506\n",
      "[00:00:41] [worker #0] ML tree search #61, logLikelihood: -553.599623\n",
      "[00:00:42] [worker #1] ML tree search #56, logLikelihood: -553.903924\n",
      "[00:00:42] [worker #0] ML tree search #63, logLikelihood: -554.539184\n",
      "[00:00:43] [worker #1] ML tree search #58, logLikelihood: -555.172570\n",
      "[00:00:43] [worker #0] ML tree search #65, logLikelihood: -554.219864\n",
      "[00:00:44] [worker #0] ML tree search #67, logLikelihood: -554.181317\n",
      "[00:00:45] [worker #1] ML tree search #60, logLikelihood: -553.553891\n",
      "[00:00:46] [worker #1] ML tree search #62, logLikelihood: -554.571543\n",
      "[00:00:46] [worker #0] ML tree search #69, logLikelihood: -554.540279\n",
      "[00:00:46] [worker #1] ML tree search #64, logLikelihood: -554.529552\n",
      "[00:00:47] [worker #0] ML tree search #71, logLikelihood: -554.788959\n",
      "[00:00:48] [worker #1] ML tree search #66, logLikelihood: -554.539714\n",
      "[00:00:49] [worker #0] ML tree search #73, logLikelihood: -554.281125\n",
      "[00:00:49] [worker #1] ML tree search #68, logLikelihood: -553.587579\n",
      "[00:00:50] [worker #0] ML tree search #75, logLikelihood: -555.200881\n",
      "[00:00:51] [worker #1] ML tree search #70, logLikelihood: -553.595838\n",
      "[00:00:51] [worker #0] ML tree search #77, logLikelihood: -553.587540\n",
      "[00:00:52] [worker #1] ML tree search #72, logLikelihood: -554.052222\n",
      "[00:00:53] [worker #0] ML tree search #79, logLikelihood: -556.610291\n",
      "[00:00:53] [worker #1] ML tree search #74, logLikelihood: -554.219432\n",
      "[00:00:54] [worker #0] ML tree search #81, logLikelihood: -554.202815\n",
      "[00:00:55] [worker #1] ML tree search #76, logLikelihood: -555.189227\n",
      "[00:00:56] [worker #0] ML tree search #83, logLikelihood: -553.596168\n",
      "[00:00:56] [worker #1] ML tree search #78, logLikelihood: -555.435475\n",
      "[00:00:58] [worker #0] ML tree search #85, logLikelihood: -554.786591\n",
      "[00:00:58] [worker #1] ML tree search #80, logLikelihood: -553.599603\n",
      "[00:00:59] [worker #1] ML tree search #82, logLikelihood: -554.785044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:00] [worker #0] ML tree search #87, logLikelihood: -554.282953\n",
      "[00:01:01] [worker #1] ML tree search #84, logLikelihood: -557.529135\n",
      "[00:01:02] [worker #0] ML tree search #89, logLikelihood: -554.699185\n",
      "[00:01:03] [worker #1] ML tree search #86, logLikelihood: -553.981237\n",
      "[00:01:04] [worker #0] ML tree search #91, logLikelihood: -554.568882\n",
      "[00:01:04] [worker #1] ML tree search #88, logLikelihood: -553.583773\n",
      "[00:01:05] [worker #0] ML tree search #93, logLikelihood: -554.220327\n",
      "[00:01:07] [worker #1] ML tree search #90, logLikelihood: -553.596237\n",
      "[00:01:07] [worker #0] ML tree search #95, logLikelihood: -554.045865\n",
      "[00:01:08] [worker #0] ML tree search #97, logLikelihood: -555.042464\n",
      "[00:01:09] [worker #1] ML tree search #92, logLikelihood: -553.599558\n",
      "[00:01:09] [worker #0] ML tree search #99, logLikelihood: -554.219709\n",
      "[00:01:10] [worker #1] ML tree search #94, logLikelihood: -556.203109\n",
      "[00:01:10] [worker #0] ML tree search #101, logLikelihood: -557.929259\n",
      "[00:01:11] [worker #1] ML tree search #96, logLikelihood: -554.219893\n",
      "[00:01:12] [worker #0] ML tree search #103, logLikelihood: -554.220168\n",
      "[00:01:13] [worker #1] ML tree search #98, logLikelihood: -555.444732\n",
      "[00:01:13] [worker #0] ML tree search #105, logLikelihood: -555.441788\n",
      "[00:01:15] [worker #0] ML tree search #107, logLikelihood: -554.784943\n",
      "[00:01:15] [worker #1] ML tree search #100, logLikelihood: -553.982475\n",
      "[00:01:16] [worker #0] ML tree search #109, logLikelihood: -556.008130\n",
      "[00:01:16] [worker #1] ML tree search #102, logLikelihood: -556.908338\n",
      "[00:01:18] [worker #1] ML tree search #104, logLikelihood: -553.595782\n",
      "[00:01:18] [worker #0] ML tree search #111, logLikelihood: -555.775522\n",
      "[00:01:19] [worker #1] ML tree search #106, logLikelihood: -554.298311\n",
      "[00:01:19] [worker #0] ML tree search #113, logLikelihood: -553.599517\n",
      "[00:01:20] [worker #1] ML tree search #108, logLikelihood: -554.049247\n",
      "[00:01:22] [worker #0] ML tree search #115, logLikelihood: -553.710365\n",
      "[00:01:22] [worker #1] ML tree search #110, logLikelihood: -555.438365\n",
      "[00:01:23] [worker #1] ML tree search #112, logLikelihood: -555.438151\n",
      "[00:01:23] [worker #0] ML tree search #117, logLikelihood: -554.553961\n",
      "[00:01:25] [worker #0] ML tree search #119, logLikelihood: -553.905341\n",
      "[00:01:26] [worker #1] ML tree search #114, logLikelihood: -554.203188\n",
      "[00:01:27] [worker #1] ML tree search #116, logLikelihood: -555.441793\n",
      "[00:01:27] [worker #0] ML tree search #121, logLikelihood: -553.588921\n",
      "[00:01:28] [worker #1] ML tree search #118, logLikelihood: -556.197769\n",
      "[00:01:29] [worker #0] ML tree search #123, logLikelihood: -555.009158\n",
      "[00:01:30] [worker #1] ML tree search #120, logLikelihood: -554.554048\n",
      "[00:01:31] [worker #0] ML tree search #125, logLikelihood: -553.583900\n",
      "[00:01:31] [worker #1] ML tree search #122, logLikelihood: -553.890734\n",
      "[00:01:32] [worker #0] ML tree search #127, logLikelihood: -554.219630\n",
      "[00:01:32] [worker #1] ML tree search #124, logLikelihood: -554.332199\n",
      "[00:01:33] [worker #1] ML tree search #126, logLikelihood: -553.706203\n",
      "[00:01:33] [worker #0] ML tree search #129, logLikelihood: -553.583919\n",
      "[00:01:35] [worker #0] ML tree search #131, logLikelihood: -555.395503\n",
      "[00:01:35] [worker #1] ML tree search #128, logLikelihood: -555.718106\n",
      "[00:01:36] [worker #1] ML tree search #130, logLikelihood: -553.553009\n",
      "[00:01:37] [worker #0] ML tree search #133, logLikelihood: -554.827938\n",
      "[00:01:38] [worker #0] ML tree search #135, logLikelihood: -555.789935\n",
      "[00:01:38] [worker #1] ML tree search #132, logLikelihood: -556.646089\n",
      "[00:01:39] [worker #1] ML tree search #134, logLikelihood: -553.551638\n",
      "[00:01:40] [worker #1] ML tree search #136, logLikelihood: -555.069000\n",
      "[00:01:40] [worker #0] ML tree search #137, logLikelihood: -554.219995\n",
      "[00:01:41] [worker #1] ML tree search #138, logLikelihood: -554.787932\n",
      "[00:01:42] [worker #0] ML tree search #139, logLikelihood: -553.605907\n",
      "[00:01:43] [worker #1] ML tree search #140, logLikelihood: -555.183828\n",
      "[00:01:43] [worker #1] ML tree search #142, logLikelihood: -555.571998\n",
      "[00:01:44] [worker #0] ML tree search #141, logLikelihood: -554.167939\n",
      "[00:01:45] [worker #0] ML tree search #143, logLikelihood: -556.278397\n",
      "[00:01:45] [worker #1] ML tree search #144, logLikelihood: -557.529005\n",
      "[00:01:46] [worker #0] ML tree search #145, logLikelihood: -555.235448\n",
      "[00:01:47] [worker #0] ML tree search #147, logLikelihood: -560.925492\n",
      "[00:01:48] [worker #1] ML tree search #146, logLikelihood: -553.590767\n",
      "[00:01:49] [worker #0] ML tree search #149, logLikelihood: -555.437074\n",
      "[00:01:49] [worker #1] ML tree search #148, logLikelihood: -555.556671\n",
      "[00:01:50] [worker #0] ML tree search #151, logLikelihood: -553.599545\n",
      "[00:01:50] [worker #1] ML tree search #150, logLikelihood: -556.466561\n",
      "[00:01:52] [worker #0] ML tree search #153, logLikelihood: -555.769185\n",
      "[00:01:53] [worker #1] ML tree search #152, logLikelihood: -555.448106\n",
      "[00:01:54] [worker #0] ML tree search #155, logLikelihood: -554.466576\n",
      "[00:01:54] [worker #1] ML tree search #154, logLikelihood: -557.517724\n",
      "[00:01:55] [worker #0] ML tree search #157, logLikelihood: -553.599578\n",
      "[00:01:55] [worker #1] ML tree search #156, logLikelihood: -555.010720\n",
      "[00:01:56] [worker #0] ML tree search #159, logLikelihood: -555.175290\n",
      "[00:01:57] [worker #1] ML tree search #158, logLikelihood: -557.528619\n",
      "[00:01:57] [worker #0] ML tree search #161, logLikelihood: -553.588262\n",
      "[00:01:58] [worker #1] ML tree search #160, logLikelihood: -554.190782\n",
      "[00:01:58] [worker #0] ML tree search #163, logLikelihood: -553.599598\n",
      "[00:01:59] [worker #1] ML tree search #162, logLikelihood: -553.596293\n",
      "[00:02:00] [worker #1] ML tree search #164, logLikelihood: -555.438578\n",
      "[00:02:00] [worker #0] ML tree search #165, logLikelihood: -555.047230\n",
      "[00:02:01] [worker #0] ML tree search #167, logLikelihood: -556.009102\n",
      "[00:02:02] [worker #1] ML tree search #166, logLikelihood: -554.049367\n",
      "[00:02:03] [worker #1] ML tree search #168, logLikelihood: -554.880317\n",
      "[00:02:04] [worker #1] ML tree search #170, logLikelihood: -559.886921\n",
      "[00:02:04] [worker #0] ML tree search #169, logLikelihood: -554.919233\n",
      "[00:02:04] [worker #1] ML tree search #172, logLikelihood: -553.601484\n",
      "[00:02:05] [worker #0] ML tree search #171, logLikelihood: -555.789374\n",
      "[00:02:06] [worker #0] ML tree search #173, logLikelihood: -553.595738\n",
      "[00:02:06] [worker #1] ML tree search #174, logLikelihood: -553.598244\n",
      "[00:02:07] [worker #1] ML tree search #176, logLikelihood: -553.700872\n",
      "[00:02:07] [worker #0] ML tree search #175, logLikelihood: -555.045987\n",
      "[00:02:08] [worker #1] ML tree search #178, logLikelihood: -553.599554\n",
      "[00:02:08] [worker #0] ML tree search #177, logLikelihood: -553.606923\n",
      "[00:02:09] [worker #1] ML tree search #180, logLikelihood: -555.700298\n",
      "[00:02:09] [worker #0] ML tree search #179, logLikelihood: -554.065008\n",
      "[00:02:10] [worker #1] ML tree search #182, logLikelihood: -553.599577\n",
      "[00:02:11] [worker #1] ML tree search #184, logLikelihood: -553.905402\n",
      "[00:02:11] [worker #0] ML tree search #181, logLikelihood: -556.289103\n",
      "[00:02:12] [worker #1] ML tree search #186, logLikelihood: -553.592013\n",
      "[00:02:12] [worker #0] ML tree search #183, logLikelihood: -554.520391\n",
      "[00:02:14] [worker #1] ML tree search #188, logLikelihood: -557.527449\n",
      "[00:02:14] [worker #0] ML tree search #185, logLikelihood: -555.717285\n",
      "[00:02:15] [worker #1] ML tree search #190, logLikelihood: -553.892231\n",
      "[00:02:16] [worker #0] ML tree search #187, logLikelihood: -555.046957\n",
      "[00:02:17] [worker #0] ML tree search #189, logLikelihood: -555.439710\n",
      "[00:02:17] [worker #1] ML tree search #192, logLikelihood: -554.550600\n",
      "[00:02:18] [worker #1] ML tree search #194, logLikelihood: -554.190792\n",
      "[00:02:19] [worker #0] ML tree search #191, logLikelihood: -555.447445\n",
      "[00:02:20] [worker #1] ML tree search #196, logLikelihood: -555.447021\n",
      "[00:02:21] [worker #1] ML tree search #198, logLikelihood: -554.219947\n",
      "[00:02:21] [worker #0] ML tree search #193, logLikelihood: -555.438336\n",
      "[00:02:22] [worker #1] ML tree search #200, logLikelihood: -553.599556\n",
      "[00:02:23] [worker #0] ML tree search #195, logLikelihood: -557.529427\n",
      "[00:02:24] [worker #0] ML tree search #197, logLikelihood: -554.787904\n",
      "[00:02:26] [worker #0] ML tree search #199, logLikelihood: -554.332279\n",
      "\n",
      "Optimized model parameters:\n",
      "\n",
      "   Partition 0: noname\n",
      "   Rate heterogeneity: GAMMA (4 cats, mean),  alpha: 99.858962 (ML),  weights&rates: (0.250000,0.875820) (0.250000,0.964712) (0.250000,1.029568) (0.250000,1.129900) \n",
      "   Base frequencies (ML): 0.646970 0.353030 \n",
      "   Substitution rates (ML): 1.000000 \n",
      "\n",
      "\n",
      "Final LogLikelihood: -553.418945\n",
      "\n",
      "AIC score: 1288.837891 / AICc score: 18032.837891 / BIC score: 1451.199148\n",
      "Free parameters (model + branch lengths): 91\n",
      "\n",
      "WARNING: Number of free parameters (K=91) is larger than alignment size (n=44).\n",
      "         This might lead to overfitting and compromise tree inference results!\n",
      "\n",
      "\n",
      "WARNING: Best ML tree contains 6 near-zero branches!\n",
      "\n",
      "Best ML tree with collapsed near-zero branches saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bing.raxml.bestTreeCollapsed\n",
      "Best ML tree saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bing.raxml.bestTree\n",
      "All ML trees saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bing.raxml.mlTrees\n",
      "Optimized model saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bing.raxml.bestModel\n",
      "\n",
      "Execution log saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bing.raxml.log\n",
      "\n",
      "Analysis started: 07-Apr-2023 16:44:10 / finished: 07-Apr-2023 16:46:37\n",
      "\n",
      "Elapsed time: 146.984 seconds\n",
      "\n",
      "\n",
      "RAxML-NG v. 1.1.0-master released on 04.08.2022 by The Exelixis Lab.\n",
      "Developed by: Alexey M. Kozlov and Alexandros Stamatakis.\n",
      "Contributors: Diego Darriba, Tomas Flouri, Benoit Morel, Sarah Lutteropp, Ben Bettisworth.\n",
      "Latest version: https://github.com/amkozlov/raxml-ng\n",
      "Questions/problems/suggestions? Please visit: https://groups.google.com/forum/#!forum/raxml\n",
      "\n",
      "System: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz, 2 cores, 15 GB RAM\n",
      "\n",
      "RAxML-NG was called at 07-Apr-2023 16:46:37 as follows:\n",
      "\n",
      "./../../tools/raxml-ng/build/bin/raxml-ng --msa data/language_alignments/morpho_filtered_ml_final.phy --model BIN --prefix data/trees/pavlos_ml_pars100rand100bin --threads 2 --seed 2 --tree pars{100},rand{100}\n",
      "\n",
      "Analysis options:\n",
      "  run mode: ML tree search\n",
      "  start tree(s): random (100) + parsimony (100)\n",
      "  random seed: 2\n",
      "  tip-inner: OFF\n",
      "  pattern compression: ON\n",
      "  per-rate scalers: OFF\n",
      "  site repeats: ON\n",
      "  fast spr radius: AUTO\n",
      "  spr subtree cutoff: 1.000000\n",
      "  branch lengths: proportional (ML estimate, algorithm: NR-FAST)\n",
      "  SIMD kernels: AVX2\n",
      "  parallelization: coarse-grained (auto), PTHREADS (2 threads), thread pinning: OFF\n",
      "\n",
      "[00:00:00] Reading alignment from file: data/language_alignments/morpho_filtered_ml_final.phy\n",
      "[00:00:00] Loaded alignment with 46 taxa and 44 sites\n",
      "\n",
      "WARNING: Sequences It and Sp are exactly identical!\n",
      "WARNING: Sequences Ice and Far are exactly identical!\n",
      "WARNING: Sequences Po and BelR are exactly identical!\n",
      "WARNING: Duplicate sequences found: 3\n",
      "\n",
      "NOTE: Reduced alignment (with duplicates and gap-only sites/taxa removed) \n",
      "NOTE: was saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bin.raxml.reduced.phy\n",
      "\n",
      "Alignment comprises 1 partitions and 44 patterns\n",
      "\n",
      "Partition 0: noname\n",
      "Model: BIN+FO\n",
      "Alignment sites / patterns: 44 / 44\n",
      "Gaps: 4.25 %\n",
      "Invariant sites: 0.00 %\n",
      "\n",
      "\n",
      "NOTE: Binary MSA file created: data/trees/pavlos_ml_pars100rand100bin.raxml.rba\n",
      "\n",
      "Parallelization scheme autoconfig: 2 worker(s) x 1 thread(s)\n",
      "\n",
      "Parallel reduction/worker buffer size: 1 KB  / 0 KB\n",
      "\n",
      "[00:00:00] Generating 100 random starting tree(s) with 46 taxa\n",
      "[00:00:00] Generating 100 parsimony starting tree(s) with 46 taxa\n",
      "[00:00:00] Data distribution: max. partitions/sites/weight per thread: 1 / 44 / 88\n",
      "[00:00:00] Data distribution: max. searches per worker: 100\n",
      "\n",
      "Starting ML tree search with 200 distinct starting trees\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:00] [worker #1] ML tree search #2, logLikelihood: -555.432518\n",
      "[00:00:00] [worker #0] ML tree search #1, logLikelihood: -553.818502\n",
      "[00:00:01] [worker #1] ML tree search #4, logLikelihood: -553.982708\n",
      "[00:00:01] [worker #0] ML tree search #3, logLikelihood: -554.152007\n",
      "[00:00:02] [worker #1] ML tree search #6, logLikelihood: -553.532595\n",
      "[00:00:02] [worker #0] ML tree search #5, logLikelihood: -553.902774\n",
      "[00:00:02] [worker #1] ML tree search #8, logLikelihood: -553.535711\n",
      "[00:00:03] [worker #0] ML tree search #7, logLikelihood: -554.724775\n",
      "[00:00:03] [worker #0] ML tree search #9, logLikelihood: -555.070576\n",
      "[00:00:03] [worker #1] ML tree search #10, logLikelihood: -557.617449\n",
      "[00:00:04] [worker #1] ML tree search #12, logLikelihood: -554.759423\n",
      "[00:00:04] [worker #0] ML tree search #11, logLikelihood: -554.759381\n",
      "[00:00:04] [worker #1] ML tree search #14, logLikelihood: -553.992696\n",
      "[00:00:05] [worker #1] ML tree search #16, logLikelihood: -554.152180\n",
      "[00:00:05] [worker #0] ML tree search #13, logLikelihood: -553.510005\n",
      "[00:00:06] [worker #1] ML tree search #18, logLikelihood: -553.532606\n",
      "[00:00:06] [worker #0] ML tree search #15, logLikelihood: -554.195751\n",
      "[00:00:06] [worker #1] ML tree search #20, logLikelihood: -554.819031\n",
      "[00:00:06] [worker #0] ML tree search #17, logLikelihood: -554.355368\n",
      "[00:00:07] [worker #1] ML tree search #22, logLikelihood: -553.509540\n",
      "[00:00:07] [worker #0] ML tree search #19, logLikelihood: -553.533085\n",
      "[00:00:07] [worker #1] ML tree search #24, logLikelihood: -553.508502\n",
      "[00:00:08] [worker #0] ML tree search #21, logLikelihood: -553.989737\n",
      "[00:00:08] [worker #1] ML tree search #26, logLikelihood: -553.534830\n",
      "[00:00:08] [worker #0] ML tree search #23, logLikelihood: -554.151597\n",
      "[00:00:09] [worker #0] ML tree search #25, logLikelihood: -554.733049\n",
      "[00:00:09] [worker #1] ML tree search #28, logLikelihood: -553.509685\n",
      "[00:00:09] [worker #0] ML tree search #27, logLikelihood: -554.628262\n",
      "[00:00:09] [worker #1] ML tree search #30, logLikelihood: -559.644473\n",
      "[00:00:10] [worker #0] ML tree search #29, logLikelihood: -554.152899\n",
      "[00:00:10] [worker #1] ML tree search #32, logLikelihood: -554.736675\n",
      "[00:00:11] [worker #0] ML tree search #31, logLikelihood: -553.811782\n",
      "[00:00:11] [worker #1] ML tree search #34, logLikelihood: -554.127722\n",
      "[00:00:11] [worker #1] ML tree search #36, logLikelihood: -554.195776\n",
      "[00:00:12] [worker #0] ML tree search #33, logLikelihood: -553.507040\n",
      "[00:00:12] [worker #1] ML tree search #38, logLikelihood: -554.120306\n",
      "[00:00:12] [worker #0] ML tree search #35, logLikelihood: -554.763286\n",
      "[00:00:12] [worker #1] ML tree search #40, logLikelihood: -557.486010\n",
      "[00:00:13] [worker #1] ML tree search #42, logLikelihood: -555.670087\n",
      "[00:00:13] [worker #0] ML tree search #37, logLikelihood: -553.573073\n",
      "[00:00:13] [worker #0] ML tree search #39, logLikelihood: -554.763292\n",
      "[00:00:13] [worker #1] ML tree search #44, logLikelihood: -555.841675\n",
      "[00:00:14] [worker #0] ML tree search #41, logLikelihood: -553.569055\n",
      "[00:00:14] [worker #1] ML tree search #46, logLikelihood: -554.354169\n",
      "[00:00:14] [worker #1] ML tree search #48, logLikelihood: -554.915550\n",
      "[00:00:14] [worker #0] ML tree search #43, logLikelihood: -553.573254\n",
      "[00:00:15] [worker #1] ML tree search #50, logLikelihood: -555.242906\n",
      "[00:00:15] [worker #0] ML tree search #45, logLikelihood: -553.631773\n",
      "[00:00:15] [worker #1] ML tree search #52, logLikelihood: -554.759090\n",
      "[00:00:15] [worker #0] ML tree search #47, logLikelihood: -555.841507\n",
      "[00:00:15] [worker #1] ML tree search #54, logLikelihood: -553.509563\n",
      "[00:00:16] [worker #0] ML tree search #49, logLikelihood: -554.767228\n",
      "[00:00:16] [worker #0] ML tree search #51, logLikelihood: -554.724683\n",
      "[00:00:16] [worker #1] ML tree search #56, logLikelihood: -554.152558\n",
      "[00:00:17] [worker #0] ML tree search #53, logLikelihood: -554.151834\n",
      "[00:00:17] [worker #1] ML tree search #58, logLikelihood: -553.573207\n",
      "[00:00:17] [worker #0] ML tree search #55, logLikelihood: -554.896488\n",
      "[00:00:18] [worker #1] ML tree search #60, logLikelihood: -554.158628\n",
      "[00:00:18] [worker #0] ML tree search #57, logLikelihood: -553.987591\n",
      "[00:00:18] [worker #1] ML tree search #62, logLikelihood: -553.532621\n",
      "[00:00:18] [worker #0] ML tree search #59, logLikelihood: -554.158279\n",
      "[00:00:19] [worker #1] ML tree search #64, logLikelihood: -555.471107\n",
      "[00:00:19] [worker #0] ML tree search #61, logLikelihood: -553.569059\n",
      "[00:00:19] [worker #0] ML tree search #63, logLikelihood: -553.982061\n",
      "[00:00:19] [worker #1] ML tree search #66, logLikelihood: -553.987399\n",
      "[00:00:20] [worker #1] ML tree search #68, logLikelihood: -554.120313\n",
      "[00:00:20] [worker #0] ML tree search #65, logLikelihood: -553.729124\n",
      "[00:00:20] [worker #1] ML tree search #70, logLikelihood: -554.626105\n",
      "[00:00:21] [worker #0] ML tree search #67, logLikelihood: -555.318842\n",
      "[00:00:21] [worker #1] ML tree search #72, logLikelihood: -555.943697\n",
      "[00:00:21] [worker #0] ML tree search #69, logLikelihood: -554.880650\n",
      "[00:00:22] [worker #1] ML tree search #74, logLikelihood: -554.758995\n",
      "[00:00:22] [worker #0] ML tree search #71, logLikelihood: -553.627845\n",
      "[00:00:22] [worker #1] ML tree search #76, logLikelihood: -554.766998\n",
      "[00:00:22] [worker #0] ML tree search #73, logLikelihood: -554.736918\n",
      "[00:00:23] [worker #1] ML tree search #78, logLikelihood: -556.071646\n",
      "[00:00:23] [worker #0] ML tree search #75, logLikelihood: -554.940663\n",
      "[00:00:23] [worker #1] ML tree search #80, logLikelihood: -553.995693\n",
      "[00:00:23] [worker #0] ML tree search #77, logLikelihood: -554.916920\n",
      "[00:00:24] [worker #1] ML tree search #82, logLikelihood: -553.987195\n",
      "[00:00:24] [worker #0] ML tree search #79, logLikelihood: -553.509556\n",
      "[00:00:24] [worker #1] ML tree search #84, logLikelihood: -554.628253\n",
      "[00:00:25] [worker #0] ML tree search #81, logLikelihood: -553.505665\n",
      "[00:00:25] [worker #1] ML tree search #86, logLikelihood: -553.509637\n",
      "[00:00:25] [worker #0] ML tree search #83, logLikelihood: -558.297594\n",
      "[00:00:25] [worker #1] ML tree search #88, logLikelihood: -553.820298\n",
      "[00:00:26] [worker #0] ML tree search #85, logLikelihood: -554.090205\n",
      "[00:00:26] [worker #1] ML tree search #90, logLikelihood: -554.741657\n",
      "[00:00:26] [worker #1] ML tree search #92, logLikelihood: -553.991183\n",
      "[00:00:26] [worker #0] ML tree search #87, logLikelihood: -555.378576\n",
      "[00:00:27] [worker #0] ML tree search #89, logLikelihood: -554.876505\n",
      "[00:00:27] [worker #1] ML tree search #94, logLikelihood: -555.698691\n",
      "[00:00:27] [worker #0] ML tree search #91, logLikelihood: -556.653328\n",
      "[00:00:27] [worker #1] ML tree search #96, logLikelihood: -554.737888\n",
      "[00:00:28] [worker #0] ML tree search #93, logLikelihood: -554.152001\n",
      "[00:00:28] [worker #0] ML tree search #95, logLikelihood: -553.729098\n",
      "[00:00:29] [worker #1] ML tree search #98, logLikelihood: -553.723329\n",
      "[00:00:29] [worker #0] ML tree search #97, logLikelihood: -555.277328\n",
      "[00:00:29] [worker #1] ML tree search #100, logLikelihood: -553.662646\n",
      "[00:00:30] [worker #0] ML tree search #99, logLikelihood: -553.629085\n",
      "[00:00:30] [worker #0] ML tree search #101, logLikelihood: -557.915899\n",
      "[00:00:30] [worker #1] ML tree search #102, logLikelihood: -555.943425\n",
      "[00:00:30] [worker #0] ML tree search #103, logLikelihood: -554.152000\n",
      "[00:00:31] [worker #1] ML tree search #104, logLikelihood: -554.740572\n",
      "[00:00:31] [worker #0] ML tree search #105, logLikelihood: -555.378253\n",
      "[00:00:31] [worker #0] ML tree search #107, logLikelihood: -555.118642\n",
      "[00:00:31] [worker #1] ML tree search #106, logLikelihood: -554.190555\n",
      "[00:00:32] [worker #0] ML tree search #109, logLikelihood: -555.926910\n",
      "[00:00:32] [worker #1] ML tree search #108, logLikelihood: -554.628368\n",
      "[00:00:33] [worker #1] ML tree search #110, logLikelihood: -558.297751\n",
      "[00:00:33] [worker #0] ML tree search #111, logLikelihood: -555.400563\n",
      "[00:00:33] [worker #0] ML tree search #113, logLikelihood: -553.505668\n",
      "[00:00:33] [worker #1] ML tree search #112, logLikelihood: -555.378373\n",
      "[00:00:34] [worker #1] ML tree search #114, logLikelihood: -555.378743\n",
      "[00:00:35] [worker #0] ML tree search #115, logLikelihood: -553.573181\n",
      "[00:00:35] [worker #1] ML tree search #116, logLikelihood: -554.152077\n",
      "[00:00:35] [worker #1] ML tree search #118, logLikelihood: -554.346063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:36] [worker #0] ML tree search #117, logLikelihood: -554.195826\n",
      "[00:00:36] [worker #1] ML tree search #120, logLikelihood: -554.196183\n",
      "[00:00:36] [worker #0] ML tree search #119, logLikelihood: -553.573090\n",
      "[00:00:36] [worker #1] ML tree search #122, logLikelihood: -554.943992\n",
      "[00:00:37] [worker #0] ML tree search #121, logLikelihood: -555.378298\n",
      "[00:00:37] [worker #1] ML tree search #124, logLikelihood: -555.841709\n",
      "[00:00:37] [worker #0] ML tree search #123, logLikelihood: -554.915411\n",
      "[00:00:38] [worker #1] ML tree search #126, logLikelihood: -556.221715\n",
      "[00:00:38] [worker #0] ML tree search #125, logLikelihood: -554.121519\n",
      "[00:00:39] [worker #0] ML tree search #127, logLikelihood: -554.152005\n",
      "[00:00:39] [worker #0] ML tree search #129, logLikelihood: -554.120358\n",
      "[00:00:39] [worker #1] ML tree search #128, logLikelihood: -555.427476\n",
      "[00:00:40] [worker #0] ML tree search #131, logLikelihood: -555.812756\n",
      "[00:00:40] [worker #1] ML tree search #130, logLikelihood: -556.224945\n",
      "[00:00:40] [worker #0] ML tree search #133, logLikelihood: -554.724821\n",
      "[00:00:41] [worker #1] ML tree search #132, logLikelihood: -556.581374\n",
      "[00:00:41] [worker #0] ML tree search #135, logLikelihood: -555.697574\n",
      "[00:00:42] [worker #1] ML tree search #134, logLikelihood: -553.571248\n",
      "[00:00:42] [worker #0] ML tree search #137, logLikelihood: -555.378824\n",
      "[00:00:43] [worker #1] ML tree search #136, logLikelihood: -554.089002\n",
      "[00:00:43] [worker #0] ML tree search #139, logLikelihood: -554.740686\n",
      "[00:00:43] [worker #1] ML tree search #138, logLikelihood: -554.158279\n",
      "[00:00:44] [worker #0] ML tree search #141, logLikelihood: -554.128004\n",
      "[00:00:44] [worker #1] ML tree search #140, logLikelihood: -553.569115\n",
      "[00:00:45] [worker #0] ML tree search #143, logLikelihood: -555.319962\n",
      "[00:00:45] [worker #1] ML tree search #142, logLikelihood: -555.471473\n",
      "[00:00:45] [worker #0] ML tree search #145, logLikelihood: -555.009104\n",
      "[00:00:46] [worker #0] ML tree search #147, logLikelihood: -555.400564\n",
      "[00:00:46] [worker #1] ML tree search #144, logLikelihood: -557.501940\n",
      "[00:00:46] [worker #0] ML tree search #149, logLikelihood: -554.120315\n",
      "[00:00:47] [worker #0] ML tree search #151, logLikelihood: -553.511053\n",
      "[00:00:47] [worker #1] ML tree search #146, logLikelihood: -554.121048\n",
      "[00:00:47] [worker #0] ML tree search #153, logLikelihood: -554.120307\n",
      "[00:00:48] [worker #1] ML tree search #148, logLikelihood: -554.120321\n",
      "[00:00:48] [worker #1] ML tree search #150, logLikelihood: -555.378253\n",
      "[00:00:49] [worker #0] ML tree search #155, logLikelihood: -555.379029\n",
      "[00:00:49] [worker #1] ML tree search #152, logLikelihood: -554.120428\n",
      "[00:00:49] [worker #0] ML tree search #157, logLikelihood: -553.509541\n",
      "[00:00:50] [worker #0] ML tree search #159, logLikelihood: -554.916256\n",
      "[00:00:50] [worker #1] ML tree search #154, logLikelihood: -554.756924\n",
      "[00:00:51] [worker #0] ML tree search #161, logLikelihood: -553.505674\n",
      "[00:00:51] [worker #1] ML tree search #156, logLikelihood: -554.914621\n",
      "[00:00:52] [worker #1] ML tree search #158, logLikelihood: -554.733704\n",
      "[00:00:52] [worker #0] ML tree search #163, logLikelihood: -554.733809\n",
      "[00:00:53] [worker #1] ML tree search #160, logLikelihood: -554.093771\n",
      "[00:00:53] [worker #0] ML tree search #165, logLikelihood: -554.765803\n",
      "[00:00:53] [worker #0] ML tree search #167, logLikelihood: -554.724693\n",
      "[00:00:53] [worker #1] ML tree search #162, logLikelihood: -556.223685\n",
      "[00:00:54] [worker #1] ML tree search #164, logLikelihood: -558.297585\n",
      "[00:00:54] [worker #0] ML tree search #169, logLikelihood: -554.856911\n",
      "[00:00:54] [worker #1] ML tree search #166, logLikelihood: -553.993690\n",
      "[00:00:55] [worker #0] ML tree search #171, logLikelihood: -553.987163\n",
      "[00:00:55] [worker #1] ML tree search #168, logLikelihood: -554.945595\n",
      "[00:00:56] [worker #0] ML tree search #173, logLikelihood: -553.508852\n",
      "[00:00:56] [worker #1] ML tree search #170, logLikelihood: -553.508869\n",
      "[00:00:57] [worker #0] ML tree search #175, logLikelihood: -553.573022\n",
      "[00:00:57] [worker #1] ML tree search #172, logLikelihood: -553.532596\n",
      "[00:00:58] [worker #0] ML tree search #177, logLikelihood: -554.086617\n",
      "[00:00:58] [worker #1] ML tree search #174, logLikelihood: -553.571037\n",
      "[00:00:58] [worker #0] ML tree search #179, logLikelihood: -555.135366\n",
      "[00:00:58] [worker #0] ML tree search #181, logLikelihood: -556.522847\n",
      "[00:00:59] [worker #1] ML tree search #176, logLikelihood: -553.627949\n",
      "[00:00:59] [worker #1] ML tree search #178, logLikelihood: -553.509576\n",
      "[00:00:59] [worker #0] ML tree search #183, logLikelihood: -554.196133\n",
      "[00:01:00] [worker #1] ML tree search #180, logLikelihood: -555.378319\n",
      "[00:01:00] [worker #0] ML tree search #185, logLikelihood: -554.199177\n",
      "[00:01:00] [worker #1] ML tree search #182, logLikelihood: -553.861542\n",
      "[00:01:00] [worker #0] ML tree search #187, logLikelihood: -557.711522\n",
      "[00:01:01] [worker #1] ML tree search #184, logLikelihood: -554.944229\n",
      "[00:01:01] [worker #0] ML tree search #189, logLikelihood: -555.379956\n",
      "[00:01:02] [worker #1] ML tree search #186, logLikelihood: -556.522846\n",
      "[00:01:02] [worker #0] ML tree search #191, logLikelihood: -555.400551\n",
      "[00:01:03] [worker #1] ML tree search #188, logLikelihood: -553.508659\n",
      "[00:01:03] [worker #0] ML tree search #193, logLikelihood: -555.432605\n",
      "[00:01:04] [worker #1] ML tree search #190, logLikelihood: -553.769550\n",
      "[00:01:05] [worker #0] ML tree search #195, logLikelihood: -554.740996\n",
      "[00:01:05] [worker #1] ML tree search #192, logLikelihood: -554.195984\n",
      "[00:01:05] [worker #0] ML tree search #197, logLikelihood: -554.120328\n",
      "[00:01:06] [worker #1] ML tree search #194, logLikelihood: -554.086185\n",
      "[00:01:06] [worker #1] ML tree search #196, logLikelihood: -555.378370\n",
      "[00:01:06] [worker #0] ML tree search #199, logLikelihood: -554.195817\n",
      "[00:01:07] [worker #1] ML tree search #198, logLikelihood: -554.152001\n",
      "[00:01:08] [worker #1] ML tree search #200, logLikelihood: -553.988276\n",
      "\n",
      "Optimized model parameters:\n",
      "\n",
      "   Partition 0: noname\n",
      "   Rate heterogeneity: NONE\n",
      "   Base frequencies (ML): 0.636802 0.363198 \n",
      "   Substitution rates (ML): 1.000000 \n",
      "\n",
      "\n",
      "Final LogLikelihood: -553.505665\n",
      "\n",
      "AIC score: 1287.011330 / AICc score: 17667.011330 / BIC score: 1447.588397\n",
      "Free parameters (model + branch lengths): 90\n",
      "\n",
      "WARNING: Number of free parameters (K=90) is larger than alignment size (n=44).\n",
      "         This might lead to overfitting and compromise tree inference results!\n",
      "\n",
      "\n",
      "WARNING: Best ML tree contains 7 near-zero branches!\n",
      "\n",
      "Best ML tree with collapsed near-zero branches saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bin.raxml.bestTreeCollapsed\n",
      "Best ML tree saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bin.raxml.bestTree\n",
      "All ML trees saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bin.raxml.mlTrees\n",
      "Optimized model saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bin.raxml.bestModel\n",
      "\n",
      "Execution log saved to: /home/luise/master_thesis/scripts/case_study_elena/data/trees/pavlos_ml_pars100rand100bin.raxml.log\n",
      "\n",
      "Analysis started: 07-Apr-2023 16:46:37 / finished: 07-Apr-2023 16:47:45\n",
      "\n",
      "Elapsed time: 68.221 seconds\n",
      "\n",
      "data/trees/pavlos_ml_pars100rand100bin_unique.raxml.interimTrees created\n",
      "data/trees/pavlos_ml_pars100rand100bing_unique.raxml.interimTrees created\n",
      "data/trees/pavlos_ml_pars100rand100bin_unique.raxml.mlTrees created\n",
      "data/trees/pavlos_ml_pars100rand100bing_unique.raxml.mlTrees created\n",
      "data/trees/pavlos_ml_all_ml.trees created\n",
      "data/trees/pavlos_ml_all_interim.trees created\n",
      "data/trees/pavlos_ml_all_start.trees created\n",
      "data/trees/pavlos_ml_all.trees created\n"
     ]
    }
   ],
   "source": [
    "def create_tree_sets(alignment_name, prefix):\n",
    "    os.system(\"./interim_trees.sh \" + alignment_name + \" \" + prefix)\n",
    "    eliminate_topological_duplicates_ete([prefix + \"pars100rand100bin.raxml.interimTrees\"], \n",
    "                                         prefix + \"pars100rand100bin_unique.raxml.interimTrees\")\n",
    "    eliminate_topological_duplicates_ete([prefix + \"pars100rand100bing.raxml.interimTrees\"], \n",
    "                                         prefix + \"pars100rand100bing_unique.raxml.interimTrees\")\n",
    "    eliminate_topological_duplicates_ete([prefix + \"pars100rand100bin.raxml.mlTrees\"], \n",
    "                                         prefix + \"pars100rand100bin_unique.raxml.mlTrees\")\n",
    "    eliminate_topological_duplicates_ete([prefix + \"pars100rand100bing.raxml.mlTrees\"], \n",
    "                                         prefix + \"pars100rand100bing_unique.raxml.mlTrees\")\n",
    "    eliminate_topological_duplicates_ete([prefix + \"pars100rand100bin_unique.raxml.mlTrees\",\n",
    "                                        prefix + \"pars100rand100bing_unique.raxml.mlTrees\"], \n",
    "                                        prefix + \"all_ml.trees\")\n",
    "    eliminate_topological_duplicates_ete([prefix + \"pars100rand100bin_unique.raxml.interimTrees\",\n",
    "                                          prefix + \"pars100rand100bing_unique.raxml.interimTrees\"],\n",
    "                                         prefix + \"all_interim.trees\")\n",
    "    eliminate_topological_duplicates_ete([prefix + \"pars100rand100bin.raxml.startTree\",\n",
    "                                          prefix + \"pars100rand100bing.raxml.startTree\"],\n",
    "                                         prefix + \"all_start.trees\")\n",
    "    eliminate_topological_duplicates_ete([prefix + \"all_start.trees\",\n",
    "                                          prefix + \"all_interim.trees\"],\n",
    "                                         prefix + \"all.trees\")\n",
    "    os.remove(\"data/trees/\" + prefix + \"pars100rand100bing.raxml.bestModel\")\n",
    "    os.remove(\"data/trees/\" + prefix + \"pars100rand100bing.raxml.log\")\n",
    "    os.remove(\"data/trees/\" + prefix + \"pars100rand100bing.raxml.rba\")\n",
    "    os.remove(\"data/trees/\" + prefix + \"pars100rand100bin.raxml.bestModel\")\n",
    "    os.remove(\"data/trees/\" + prefix + \"pars100rand100bin.raxml.log\")\n",
    "    os.remove(\"data/trees/\" + prefix + \"pars100rand100bin.raxml.rba\")\n",
    "    \n",
    "    \n",
    "    \n",
    "create_tree_sets(\"morpho_filtered_ml_final.phy\", \"pavlos_ml_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f23ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
